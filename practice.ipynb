{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# 접속 정보\n",
    "host = \"10.28.224.177\"\n",
    "port = 30634\n",
    "database = \"postgres\"\n",
    "username = \"postgres\"\n",
    "password = \"0104\"\n",
    "\n",
    "# SQLAlchemy 엔진 생성\n",
    "engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "query = f'SELECT * FROM public.\"Comments\"'\n",
    "comments_df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   viewcount  likecount  commentcount  videocount\n",
      "0   650339.0   0.069132      0.005322           7\n",
      "Index(['viewcount', 'likecount', 'commentcount', 'videocount'], dtype='object')\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncpg\n",
    "\n",
    "# db 접속하기\n",
    "conn = await asyncpg.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",  \n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "        )\n",
    "query = f\"\"\"\n",
    "        SELECT\n",
    "                SUM(CAST(v.\"videoViewCount\" AS FLOAT)) FILTER (WHERE TO_TIMESTAMP(\"videoPublishedAt\", 'YYYY-MM-DD') >= CURRENT_DATE - INTERVAL '90 days') AS viewcount,\n",
    "                SUM(CAST(v.\"videoLikeCount\" AS FLOAT)/NULLIF(CAST(v.\"videoViewCount\" AS FLOAT), 0)) FILTER (WHERE TO_TIMESTAMP(\"videoPublishedAt\", 'YYYY-MM-DD') >= CURRENT_DATE - INTERVAL '90 days') AS likecount,\n",
    "                SUM(CAST(v.\"commentCount\" AS FLOAT)/NULLIF(CAST(v.\"videoViewCount\" AS FLOAT), 0)) FILTER (WHERE TO_TIMESTAMP(\"videoPublishedAt\", 'YYYY-MM-DD') >= CURRENT_DATE - INTERVAL '90 days') AS commentcount,\n",
    "                COUNT(*) FILTER (WHERE TO_TIMESTAMP(\"videoPublishedAt\", 'YYYY-MM-DD') >= CURRENT_DATE - INTERVAL '90 days') AS videocount\n",
    "        FROM public.\"Video\" v\n",
    "        LEFT JOIN public.\"Channel\" c\n",
    "        ON v.\"channel_id\" = c.\"id\"\n",
    "        WHERE v.\"channel_id\" = '{6}' AND v.\"hasPaidProductPlacement\" = false\n",
    "        GROUP BY c.\"id\", c.\"viewCount\";\n",
    "        \"\"\"\n",
    "\n",
    "rows = await conn.fetch(query)\n",
    "df = pd.DataFrame(rows, columns=[key for key in rows[0].keys()])\n",
    "#name_to_id = {name:int(id) for name, id in zip(df['title'].values, df['id'].values)}\n",
    "print(df)\n",
    "#print(len(df))\n",
    "print(df.columns)\n",
    "print(name_to_id['동하하'])\n",
    "await conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table 아예 지우고 덮어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncpg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "async def overwrite_table_with_csv(file_path, table_name):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "\n",
    "    '''# Ensure proper data types\n",
    "    for col in ['dailySubscriberCount', 'dailyViewCount', 'totalSubscriberCount', 'totalViewCount']:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype('Int64')  # Nullable integer type'''\n",
    "    data = data.replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "    # Convert rows to tuples\n",
    "    rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "    \n",
    "    # PostgreSQL 연결\n",
    "    conn = await asyncpg.connect(\n",
    "    \t\thost=\"10.28.224.177\",\n",
    "            port=\"30634\",  \n",
    "            user=\"postgres\",\n",
    "            password=\"0104\",\n",
    "            database=\"postgres\"\n",
    "            )\n",
    "\n",
    "    try:\n",
    "        await conn.execute(f\"TRUNCATE TABLE {table_name};\")\n",
    "        print(f\"Table {table_name} truncated.\")\n",
    "        \n",
    "        # 데이터 삽입\n",
    "        columns = ['\"'+column+'\"' for column in list(data.columns)]\n",
    "        print(*columns)\n",
    "        values_placeholder = \", \".join([f\"${i+1}\" for i in range(len(columns))])\n",
    "        insert_query = f\"\"\"INSERT INTO \"{table_name}\" ({', '.join(columns)}) VALUES ({values_placeholder});\"\"\"\n",
    "\n",
    "        # 데이터 행 생성\n",
    "        rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "        await conn.executemany(insert_query, rows)\n",
    "        print(f\"\"\"{len(rows)} rows inserted into \"{table_name}\".\"\"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        await conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    await overwrite_table_with_csv(csv_path, table_name)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: relation \"channel\" does not exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def overwrite_table_with_csv(file_path, table_name):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # NaN 값을 None으로 변환 (PostgreSQL에서 NULL로 처리)\n",
    "    data = data.replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "    # 데이터 행을 튜플 형태로 변환\n",
    "    rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "\n",
    "    # PostgreSQL 연결\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",\n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # 테이블 비우기 (TRUNCATE)\n",
    "            cur.execute(f\"TRUNCATE TABLE {table_name};\")\n",
    "            print(f\"Table {table_name} truncated.\")\n",
    "\n",
    "            # 데이터 삽입 쿼리 생성\n",
    "            columns = ['\"'+column+'\"' for column in list(data.columns)]\n",
    "            values_placeholder = \", \".join([\"%s\"] * len(columns))\n",
    "            insert_query = f\"\"\"INSERT INTO \"{table_name}\" ({', '.join(columns)}) VALUES ({values_placeholder});\"\"\"\n",
    "\n",
    "            # 데이터 삽입 실행\n",
    "            cur.executemany(insert_query, rows)\n",
    "            print(f\"{len(rows)} rows inserted into '{table_name}'.\")\n",
    "\n",
    "        # 변경사항 커밋\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"                  # 테이블 이름\n",
    "    overwrite_table_with_csv(csv_path, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 row에 데이터 추가 (UPDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20, 1242), (1, 0, 0), (2, 60, 2713), (3, 660, 241), (4, 24, 957), (5, 2, 2288), (6, 0, 0), (7, 40, 8800), (8, 2, 2723), (9, 0, 0)]\n",
      "\"NumLiveBroadcasting\" \"AverageViewerCount\"\n",
      "10 rows inserted into \"Channel\".\n"
     ]
    }
   ],
   "source": [
    "import asyncpg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "async def overwrite_table_with_csv(file_path, table_name, columns):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    rows = [tuple(row) for row in data[['id'] + columns].itertuples(index=False, name=None)]\n",
    "    print(rows)\n",
    "    # PostgreSQL 연결\n",
    "    conn = await asyncpg.connect(\n",
    "    \t\thost=\"10.28.224.177\",\n",
    "            port=\"30634\",  \n",
    "            user=\"postgres\",\n",
    "            password=\"0104\",\n",
    "            database=\"postgres\"\n",
    "            )\n",
    "\n",
    "    try:\n",
    "        # 데이터 삽입\n",
    "        columns = ['\"'+column+'\"' for column in columns]\n",
    "        print(*columns)\n",
    "        values_placeholder = \", \".join([f\"{col} = ${i+2}\" for i, col in enumerate(columns)])\n",
    "        insert_query = f\"\"\"\n",
    "        UPDATE \"{table_name}\"\n",
    "        SET {values_placeholder}\n",
    "        WHERE \"id\" = $1;\n",
    "        \"\"\" \n",
    "\n",
    "        await conn.executemany(insert_query, rows)\n",
    "        print(f\"\"\"{len(rows)} rows inserted into \"{table_name}\".\"\"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        await conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    csv_path = \"라이브 영상 수.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    columns = [\"NumLiveBroadcasting\", \"AverageViewerCount\"]\n",
    "    await overwrite_table_with_csv(csv_path, table_name, columns)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumLiveBroadcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverageViewerCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m overwrite_table_with_csv(csv_path, table_name, columns)\n\u001b[0;32m---> 56\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def overwrite_table_with_csv(file_path, table_name,):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    columns = data.columns\n",
    "    rows = [tuple(row) for row in data[['id'] + columns].itertuples(index=False, name=None)]\n",
    "    \n",
    "    # PostgreSQL 연결\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",\n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "    )\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # 정렬된 새 테이블 생성\n",
    "            create_query = f\"\"\"\n",
    "            CREATE TABLE Channel_Sorted AS\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "            ORDER BY id;\n",
    "            \n",
    "            -- 기존 테이블 삭제\n",
    "            DROP TABLE {table_name};\n",
    "            \n",
    "            -- 새 테이블 이름 변경\n",
    "            ALTER TABLE Channel_Sorted RENAME TO {table_name};\n",
    "            \"\"\"\n",
    "            cur.execute(create_query)\n",
    "\n",
    "            # 데이터 삽입\n",
    "            columns_str = \", \".join(['\"id\"'] + [f'\"{col}\"' for col in columns])\n",
    "            values_placeholder = \", \".join([\"%s\"] * len(columns))\n",
    "            \n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} ({columns_str})\n",
    "            VALUES ({values_placeholder});\n",
    "            \"\"\"\n",
    "            \n",
    "            cur.executemany(insert_query, rows)\n",
    "            \n",
    "        conn.commit()\n",
    "        print(f\"{len(rows)} rows inserted into '{table_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    overwrite_table_with_csv(csv_path, table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
