{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "# 접속 정보\n",
    "host = \"10.28.224.177\"\n",
    "port = 30634\n",
    "database = \"postgres\"\n",
    "username = \"postgres\"\n",
    "password = \"0104\"\n",
    "\n",
    "# SQLAlchemy 엔진 생성\n",
    "engine = create_engine(f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "query = f'SELECT * FROM public.\"Comments\"'\n",
    "comments_df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    viewCount Donation  avg_viewcount avg_donation\n",
      "0  2179523566     None    819335238.3         None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'avg_Donation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/hwk_workspace/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avg_Donation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#print(len(df))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#print(df.columns)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_Donation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_id\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/hwk_workspace/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/hwk_workspace/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'avg_Donation'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncpg\n",
    "\n",
    "# db 접속하기\n",
    "conn = await asyncpg.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",  \n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "        )\n",
    "query = f\"\"\"\n",
    "    SELECT \"viewCount\", \"Donation\",\n",
    "        (SELECT AVG(CAST(\"viewCount\" as float)) FROM \"Channel\") as avg_viewcount,\n",
    "        (SELECT AVG(CAST(\"Donation\" as float)) FROM \"Channel\") as avg_donation\n",
    "    FROM public.\"Channel\"\n",
    "    WHERE \"name\" = '피식대학'\n",
    "    \"\"\"\n",
    "\n",
    "rows = await conn.fetch(query)\n",
    "df = pd.DataFrame(rows, columns=[key for key in rows[0].keys()])\n",
    "print(df)\n",
    "#print(len(df))\n",
    "#print(df.columns)\n",
    "print(df['avg_Donation'])\n",
    "print(type(df.iloc[0]['channel_id']))\n",
    "print('-------------------------------------------------')\n",
    "view_profit_user = (df['viewCount'])*2, int(df['viewCount']*4.5)\n",
    "view_profit_avg = (df['avg_viewCount']*2, int(df['avg_viewCount']*4.5))\n",
    "donation_profit_user = df['Donation']\n",
    "donation_profit_avg = df['avg_Donation']\n",
    "#print(df.iloc[0][\"videoDescription\"])\n",
    "await conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# table 아예 지우고 덮어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncpg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "async def overwrite_table_with_csv(file_path, table_name):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "\n",
    "    '''# Ensure proper data types\n",
    "    for col in ['dailySubscriberCount', 'dailyViewCount', 'totalSubscriberCount', 'totalViewCount']:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype('Int64')  # Nullable integer type'''\n",
    "    data = data.replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "    # Convert rows to tuples\n",
    "    rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "    \n",
    "    # PostgreSQL 연결\n",
    "    conn = await asyncpg.connect(\n",
    "    \t\thost=\"10.28.224.177\",\n",
    "            port=\"30634\",  \n",
    "            user=\"postgres\",\n",
    "            password=\"0104\",\n",
    "            database=\"postgres\"\n",
    "            )\n",
    "\n",
    "    try:\n",
    "        await conn.execute(f\"TRUNCATE TABLE {table_name};\")\n",
    "        print(f\"Table {table_name} truncated.\")\n",
    "        \n",
    "        # 데이터 삽입\n",
    "        columns = ['\"'+column+'\"' for column in list(data.columns)]\n",
    "        print(*columns)\n",
    "        values_placeholder = \", \".join([f\"${i+1}\" for i in range(len(columns))])\n",
    "        insert_query = f\"\"\"INSERT INTO \"{table_name}\" ({', '.join(columns)}) VALUES ({values_placeholder});\"\"\"\n",
    "\n",
    "        # 데이터 행 생성\n",
    "        rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "        await conn.executemany(insert_query, rows)\n",
    "        print(f\"\"\"{len(rows)} rows inserted into \"{table_name}\".\"\"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        await conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    await overwrite_table_with_csv(csv_path, table_name)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: relation \"channel\" does not exist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def overwrite_table_with_csv(file_path, table_name):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # NaN 값을 None으로 변환 (PostgreSQL에서 NULL로 처리)\n",
    "    data = data.replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "    # 데이터 행을 튜플 형태로 변환\n",
    "    rows = [tuple(row) for row in data.itertuples(index=False, name=None)]\n",
    "\n",
    "    # PostgreSQL 연결\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",\n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # 테이블 비우기 (TRUNCATE)\n",
    "            cur.execute(f\"TRUNCATE TABLE {table_name};\")\n",
    "            print(f\"Table {table_name} truncated.\")\n",
    "\n",
    "            # 데이터 삽입 쿼리 생성\n",
    "            columns = ['\"'+column+'\"' for column in list(data.columns)]\n",
    "            values_placeholder = \", \".join([\"%s\"] * len(columns))\n",
    "            insert_query = f\"\"\"INSERT INTO \"{table_name}\" ({', '.join(columns)}) VALUES ({values_placeholder});\"\"\"\n",
    "\n",
    "            # 데이터 삽입 실행\n",
    "            cur.executemany(insert_query, rows)\n",
    "            print(f\"{len(rows)} rows inserted into '{table_name}'.\")\n",
    "\n",
    "        # 변경사항 커밋\n",
    "        conn.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"                  # 테이블 이름\n",
    "    overwrite_table_with_csv(csv_path, table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 row에 데이터 추가 (UPDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 20, 1242), (1, 0, 0), (2, 60, 2713), (3, 660, 241), (4, 24, 957), (5, 2, 2288), (6, 0, 0), (7, 40, 8800), (8, 2, 2723), (9, 0, 0)]\n",
      "\"NumLiveBroadcasting\" \"AverageViewerCount\"\n",
      "10 rows inserted into \"Channel\".\n"
     ]
    }
   ],
   "source": [
    "import asyncpg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "async def overwrite_table_with_csv(file_path, table_name, columns):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    rows = [tuple(row) for row in data[['id'] + columns].itertuples(index=False, name=None)]\n",
    "    print(rows)\n",
    "    # PostgreSQL 연결\n",
    "    conn = await asyncpg.connect(\n",
    "    \t\thost=\"10.28.224.177\",\n",
    "            port=\"30634\",  \n",
    "            user=\"postgres\",\n",
    "            password=\"0104\",\n",
    "            database=\"postgres\"\n",
    "            )\n",
    "\n",
    "    try:\n",
    "        # 데이터 삽입\n",
    "        columns = ['\"'+column+'\"' for column in columns]\n",
    "        print(*columns)\n",
    "        values_placeholder = \", \".join([f\"{col} = ${i+2}\" for i, col in enumerate(columns)])\n",
    "        insert_query = f\"\"\"\n",
    "        UPDATE \"{table_name}\"\n",
    "        SET {values_placeholder}\n",
    "        WHERE \"id\" = $1;\n",
    "        \"\"\" \n",
    "\n",
    "        await conn.executemany(insert_query, rows)\n",
    "        print(f\"\"\"{len(rows)} rows inserted into \"{table_name}\".\"\"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        await conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    csv_path = \"라이브 영상 수.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    columns = [\"NumLiveBroadcasting\", \"AverageViewerCount\"]\n",
    "    await overwrite_table_with_csv(csv_path, table_name, columns)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumLiveBroadcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverageViewerCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m overwrite_table_with_csv(csv_path, table_name, columns)\n\u001b[0;32m---> 56\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def overwrite_table_with_csv(file_path, table_name,):\n",
    "    # CSV 파일 읽기\n",
    "    data = pd.read_csv(file_path)\n",
    "    columns = data.columns\n",
    "    rows = [tuple(row) for row in data[['id'] + columns].itertuples(index=False, name=None)]\n",
    "    \n",
    "    # PostgreSQL 연결\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"10.28.224.177\",\n",
    "        port=\"30634\",\n",
    "        user=\"postgres\",\n",
    "        password=\"0104\",\n",
    "        database=\"postgres\"\n",
    "    )\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # 정렬된 새 테이블 생성\n",
    "            create_query = f\"\"\"\n",
    "            CREATE TABLE Channel_Sorted AS\n",
    "            SELECT *\n",
    "            FROM {table_name}\n",
    "            ORDER BY id;\n",
    "            \n",
    "            -- 기존 테이블 삭제\n",
    "            DROP TABLE {table_name};\n",
    "            \n",
    "            -- 새 테이블 이름 변경\n",
    "            ALTER TABLE Channel_Sorted RENAME TO {table_name};\n",
    "            \"\"\"\n",
    "            cur.execute(create_query)\n",
    "\n",
    "            # 데이터 삽입\n",
    "            columns_str = \", \".join(['\"id\"'] + [f'\"{col}\"' for col in columns])\n",
    "            values_placeholder = \", \".join([\"%s\"] * len(columns))\n",
    "            \n",
    "            insert_query = f\"\"\"\n",
    "            INSERT INTO {table_name} ({columns_str})\n",
    "            VALUES ({values_placeholder});\n",
    "            \"\"\"\n",
    "            \n",
    "            cur.executemany(insert_query, rows)\n",
    "            \n",
    "        conn.commit()\n",
    "        print(f\"{len(rows)} rows inserted into '{table_name}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# 실행 코드\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"_Channel__202501271549.csv\"  # CSV 파일 경로\n",
    "    table_name = \"Channel\"         # 테이블 이름\n",
    "    overwrite_table_with_csv(csv_path, table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
